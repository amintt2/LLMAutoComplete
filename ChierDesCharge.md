# Cahier des Charges : Auto-compl√©tion Locale Intelligente (v4)

---

## 1. Objectifs ‚ú®

*   **Compl√©tion en temps r√©el :** Fonctionne discr√®tement avec toutes vos applications (sauf celles que vous excluez !).
*   **IA 100% locale :** Mod√®les de langage (1B ou 3B) rapides et respectueux de votre vie priv√©e (Llama.cpp).
*   **S√©curit√© renforc√©e :** Aucune donn√©e ne quitte votre machine. Conception anti-intrusion.
*   **Multiplateforme :** Windows, macOS, Linux, on est partout !
*   **Ultra-personnalisable :** Adaptez l'outil √† vos besoins (suggestions, zones de texte, etc.).

---

## 2. Architecture & Technologies ‚öôÔ∏è

### Approche G√©n√©rale

*   **D√©veloppement natif par plateforme :** Code sp√©cifique √† chaque OS pour une int√©gration optimale.
    *   **macOS :** Input Method Editor (IME) avec Input Method Kit (Swift/Objective-C).
    *   **Windows :** Text Services Framework (TSF) IME (C#/C++).
    *   **Linux :** Module IBus/Fcitx (C/C++/Python).
*   **Architecture commune :**
    *   Service/d√©mon en arri√®re-plan (langage natif) : Capture de texte, inf√©rence LLM (Llama.cpp), communication inter-processus (IPC).
    *   Interface utilisateur (langage natif ou React avec un pont) : Affichage des suggestions, param√®tres.
* **Communication Inter-Processus (IPC):**
    *   Chaque version pourra utiliser une architecture en deux volets : un service de capture et d'inf√©rence (√©crit dans un langage performant adapt√© √† l'OS) et une interface utilisateur (native). La communication entre ces modules se fera par des m√©canismes d'IPC adapt√©s (sockets, pipes nomm√©s, ou API sp√©cifiques).

### C≈ìur du Syst√®me (Commun)

*   **Moteur d'inf√©rence :** Int√©gration optimis√©e de Llama.cpp (bindings C).
*   **Capture de texte intelligente :**
    *   Techniques avanc√©es : API natives + OCR (Tesseract, etc.) en secours.
    *   R√©activit√© : D√©clenchement uniquement en cas de changement important (m√©thode √† choisir).

### Interface & Orchestration

*   **Logique applicative :** Gestion des √©v√©nements, appels au moteur d'inf√©rence.
*   **Interface utilisateur :** Native (Swift/Objective-C, C#/C++, framework natif Linux) ou React (avec un pont vers le code natif).

---

## 3. Fonctionnalit√©s Cl√©s üîë

1.  **Capture de texte :**
    *   D√©tection intelligente des changements √† l'√©cran.
    *   Priorit√© aux API natives, OCR en secours.
    *   Gestion des erreurs OCR.

2.  **Traitement LLM :**
    *   Llama.cpp au c≈ìur.
    *   Fine-tuning local (optionnel) :
        *   Donn√©es : Vos logs anonymis√©s (avec votre accord !) ou donn√©es open source.
        *   Outils : Hugging Face Transformers, etc.
    *   Gestion des mod√®les :
        *   T√©l√©chargement facile (m√©thode √† choisir) et s√©lection (1B, 3B, versions fine-tun√©es).
        *   Stockage local s√©curis√©, mises √† jour avec v√©rification d'int√©grit√©.
    *   Optimisation : Vitesse maximale (quantification, batching, etc.).

3.  **Interface Utilisateur :**
    *   Discr√®te : Suggestions "l√©g√®rement gris√©es" (m√©thode d'affichage √† pr√©ciser).
    *   Intuitive : Navigation clavier/souris.
    *   Personnalisable : Param√®tres pour tout contr√¥ler.
    *   Design coh√©rent entre les plateformes, respectant les guidelines de chaque OS.

4.  **Workflow Utilisateur :**
    1.  Vous tapez.
    2.  Le code natif d√©tecte un changement.
    3.  Le texte est captur√©.
    4.  Llama.cpp propose des suggestions.
    5.  Le code natif transmet √† l'interface.
    6.  Vous choisissez (ou pas) avec Tab.

---

## 4. Qualit√©, S√©curit√© & √âthique ‚úÖ

*   **Tests rigoureux :** Unitaires, int√©gration, syst√®me, performance (sp√©cifiques √† chaque plateforme). Int√©gration continue (CI) *pour chaque plateforme*.
*   **Gestion des erreurs :** Messages clairs et solutions propos√©es.
*   **S√©curit√© sans compromis :** Analyse des risques, permissions limit√©es, sandboxing, chiffrement (√† discuter).
*   **Transparence :** Licence open source, information claire sur les donn√©es.

---

## 5. Points √† Finaliser üéØ

1.  **Framework d'interface utilisateur :** Natif ou React (avec pont) ?
2.  **D√©tection de changement :** Pr√©ciser la m√©thode.
3.  **T√©l√©chargement des mod√®les :** Choisir la m√©thode (direct, BitTorrent).
4.  **Affichage des suggestions :** Pr√©ciser la m√©thode (superposition, etc.).
5.  **Communication inter-processus (IPC) :** Choix sp√©cifique pour chaque plateforme (sockets, pipes nomm√©s, etc.).
6.  **Gestion du cycle de vie de Llama.cpp :** Comment le g√©rez-vous (d√©marrage, arr√™t, red√©marrage en cas d'erreur)?
7.  **Coh√©rence multiplateforme :** Comment assurer une exp√©rience utilisateur coh√©rente malgr√© les diff√©rences techniques ? (Guide de style commun, API de configuration commune, etc.)

---
## Sp√©cifications Techniques par Syst√®me d'Exploitation

### macOS

*   **M√©canisme de saisie :** Input Method Editor (IME) bas√© sur l'Input Method Kit.
*   **Langages :** Swift ou Objective-C.
*   **Interface Utilisateur :** Interface native (overlay) respectant les guidelines Apple.
*   **Tests :** macOS Catalina et versions ult√©rieures.

### Windows

*   **M√©canisme de saisie :** Text Services Framework (TSF) IME.
*   **Langages :** C# (.NET) ou C++.
*   **Interface Utilisateur :** Overlay l√©ger et modulable, int√©gr√© avec les notifications Windows.
*   **Tests :** Windows 10 et Windows 11.

### Linux

*   **M√©canisme de saisie :** Module pour IBus ou Fcitx.
*   **Langages :** C/C++ ou Python.
*   **Interface Utilisateur :** Interface graphique (overlay) s'int√©grant avec l'environnement de bureau (GNOME, KDE, etc.).
*   **Tests :** Universalit√© sur plusieurs distributions (Ubuntu, Fedora, etc.).

---